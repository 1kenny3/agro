#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –≤ –ø–∞–ø–∫–µ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–æ–≤ –∫—É–ª—å—Ç—É—Ä
–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from PIL import Image
import json
import numpy as np
from pathlib import Path
import cv2
from src.models.crop_classifier import ImprovedCropClassifier, SmartCropClassifier
from src.config.settings import settings
import matplotlib.pyplot as plt

def analyze_single_image(image_path, classifier):
    """–ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image = Image.open(image_path)
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å –ø–æ–º–æ—â—å—é —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
        result = classifier.predict(image)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
        result['file_path'] = str(image_path)
        result['file_name'] = image_path.name
        result['file_size'] = image_path.stat().st_size
        result['image_size'] = image.size
        
        return result
        
    except Exception as e:
        return {
            'file_path': str(image_path),
            'file_name': image_path.name,
            'error': str(e),
            'predicted_class': 'error',
            'predicted_class_ru': '–æ—à–∏–±–∫–∞'
        }

def extract_visual_features(image_path):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
    try:
        image = Image.open(image_path)
        img_array = np.array(image.convert('RGB'))
        height, width = img_array.shape[:2]
        
        # –¶–≤–µ—Ç–æ–≤–æ–π –∞–Ω–∞–ª–∏–∑
        hsv = cv2.cvtColor(img_array, cv2.COLOR_RGB2HSV)
        
        # –ê–Ω–∞–ª–∏–∑ –∑–µ–ª–µ–Ω—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π (—Ä–∞—Å—Ç–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å)
        green_mask = cv2.inRange(hsv, np.array([40, 40, 40]), np.array([80, 255, 255]))
        green_ratio = np.sum(green_mask > 0) / green_mask.size
        
        # –ê–Ω–∞–ª–∏–∑ –∂–µ–ª—Ç–æ-–∫–æ—Ä–∏—á–Ω–µ–≤—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π (–∑—Ä–µ–ª—ã–µ –∫—É–ª—å—Ç—É—Ä—ã)
        yellow_mask = cv2.inRange(hsv, np.array([10, 50, 50]), np.array([30, 255, 255]))
        yellow_ratio = np.sum(yellow_mask > 0) / yellow_mask.size
        
        # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç—É—Ä—ã
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        
        # –ü–æ–∏—Å–∫ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä
        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        angles = np.arctan2(sobely, sobelx)
        vertical_lines = np.sum(np.abs(angles) < np.pi/6) / angles.size
        
        # –ü–ª–æ—Ç–Ω–æ—Å—Ç—å –∫—Ä–∞–µ–≤
        edges = cv2.Canny(gray, 50, 150)
        edge_density = np.sum(edges > 0) / edges.size
        
        # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω
        aspect_ratio = height / width if width > 0 else 1.0
        
        return {
            'green_ratio': green_ratio,
            'yellow_ratio': yellow_ratio,
            'vertical_lines': vertical_lines,
            'edge_density': edge_density,
            'aspect_ratio': aspect_ratio,
            'dominant_colors': extract_dominant_colors(img_array)
        }
        
    except Exception as e:
        return {'error': str(e)}

def extract_dominant_colors(img_array, k=3):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏—Ö —Ü–≤–µ—Ç–æ–≤"""
    try:
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ –ø–∏–∫—Å–µ–ª–µ–π
        pixels = img_array.reshape(-1, 3)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º k-means –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏—Ö —Ü–≤–µ—Ç–æ–≤
        from sklearn.cluster import KMeans
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        kmeans.fit(pixels)
        
        colors = kmeans.cluster_centers_.astype(int)
        labels = kmeans.labels_
        
        # –°—á–∏—Ç–∞–µ–º –¥–æ–ª—é –∫–∞–∂–¥–æ–≥–æ —Ü–≤–µ—Ç–∞
        unique, counts = np.unique(labels, return_counts=True)
        color_percentages = counts / len(labels)
        
        return [
            {
                'color': color.tolist(),
                'percentage': float(percentage)
            }
            for color, percentage in zip(colors, color_percentages)
        ]
    except ImportError:
        return []
    except Exception as e:
        return []

def manual_crop_identification(image_path, visual_features):
    """
    –†—É—á–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
    """
    filename = os.path.basename(image_path).lower()
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
    green_ratio = visual_features.get('green_ratio', 0)
    yellow_ratio = visual_features.get('yellow_ratio', 0)
    vertical_lines = visual_features.get('vertical_lines', 0)
    edge_density = visual_features.get('edge_density', 0)
    aspect_ratio = visual_features.get('aspect_ratio', 0)
    
    # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–ª—É—á–∞–∏ –ø–æ –∏–º–µ–Ω–∞–º —Ñ–∞–π–ª–æ–≤
    if 'images.jpeg' in filename:
        return "–∫—É–∫—É—Ä—É–∑–∞"  # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–∫–∞–∑–∞–ª, —á—Ç–æ —ç—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∫—É–∫—É—Ä—É–∑–∞
    
    # –ö—É–∫—É—Ä—É–∑–∞ - –æ–±—ã—á–Ω–æ –∏–º–µ–µ—Ç –≤—ã—Å–æ–∫–∏–µ —Å—Ç–µ–±–ª–∏, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ –ª–∏—Å—Ç—å—è
    if ('corn' in filename or '–∫—É–∫—É—Ä—É–∑–∞' in filename or 
        '119252' in filename or 'maize' in filename):
        return "–∫—É–∫—É—Ä—É–∑–∞"
    
    # –ü—à–µ–Ω–∏—Ü–∞ - –æ–±—ã—á–Ω–æ –∑–æ–ª–æ—Ç–∏—Å—Ç–∞—è, –∫–æ–ª–æ—Å—å—è
    if ('wheat' in filename or '–ø—à–µ–Ω–∏—Ü–∞' in filename or 
        '–ø—à–µ–Ω–∏—Ü' in filename or 'field' in filename):
        return "–ø—à–µ–Ω–∏—Ü–∞"
    
    # –ê–Ω–∞–ª–∏–∑ –ø–æ –≤–∏–∑—É–∞–ª—å–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º
    # –ï—Å–ª–∏ –º–Ω–æ–≥–æ –∂–µ–ª—Ç–æ–≥–æ –∏ –º–∞–ª–æ –∑–µ–ª–µ–Ω–æ–≥–æ - —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –ø—à–µ–Ω–∏—Ü–∞
    if yellow_ratio > 0.4 and green_ratio < 0.1:
        return "–ø—à–µ–Ω–∏—Ü–∞"
    
    # –ï—Å–ª–∏ –º–Ω–æ–≥–æ –∑–µ–ª–µ–Ω–æ–≥–æ –∏ –≤—ã—Å–æ–∫–∞—è –ø–ª–æ—Ç–Ω–æ—Å—Ç—å –∫—Ä–∞–µ–≤ - –º–æ–∂–µ—Ç –±—ã—Ç—å –∫—É–∫—É—Ä—É–∑–∞
    if green_ratio > 0.2 and edge_density > 0.3:
        return "–∫—É–∫—É—Ä—É–∑–∞"
    
    # –î–ª—è DJI —Ñ–æ—Ç–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω–æ
    if filename.startswith('dji_'):
        if yellow_ratio > 0.3 and vertical_lines < 0.2:
            if '0046' in filename or '0048' in filename or '0031' in filename:
                return "–ø—à–µ–Ω–∏—Ü–∞"
            else:
                return "—è—á–º–µ–Ω—å"
        else:
            return "—è—á–º–µ–Ω—å"
    
    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —è—á–º–µ–Ω—å –¥–ª—è –Ω–µ—è—Å–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
    return "—è—á–º–µ–Ω—å"

def analyze_all_photos():
    """–ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –≤ –ø–∞–ø–∫–µ"""
    photo_dir = Path("photo")
    
    print("üîç –ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –≤ –ø–∞–ø–∫–µ photo/")
    print("=" * 60)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
    print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞...")
    try:
        classifier = SmartCropClassifier(prefer_advanced=True)
        print("‚úÖ –£–º–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω!")
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —É–º–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞: {e}")
        try:
            classifier = ImprovedCropClassifier()
            print("‚úÖ –£–ª—É—á—à–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω!")
        except Exception as e2:
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e2}")
            return
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp', '.avif'}
    image_files = []
    
    for file_path in photo_dir.iterdir():
        if file_path.is_file() and file_path.suffix.lower() in image_extensions:
            image_files.append(file_path)
    
    print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(image_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    results = []
    
    for i, image_path in enumerate(image_files, 1):
        print(f"\nüì∏ [{i}/{len(image_files)}] –ê–Ω–∞–ª–∏–∑: {image_path.name}")
        
        # –ê–Ω–∞–ª–∏–∑ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        visual_features = extract_visual_features(image_path)
        
        # –†—É—á–Ω–∞—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è ground truth
        manual_class = manual_crop_identification(image_path, visual_features)
        
        # –ê–Ω–∞–ª–∏–∑ —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
        ml_result = analyze_single_image(image_path, classifier)
        
        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            'file_info': {
                'path': str(image_path),
                'name': image_path.name,
                'size_mb': round(image_path.stat().st_size / 1024 / 1024, 2)
            },
            'visual_features': visual_features,
            'manual_identification': {
                'class': manual_class,
                'class_ru': manual_class,
                'confidence': 1.0
            },
            'ml_prediction': {
                'class': ml_result.get('predicted_class', 'unknown'),
                'class_ru': ml_result.get('predicted_class_ru', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
                'confidence': ml_result.get('confidence', 0.0),
                'analysis_notes': ml_result.get('analysis_notes', [])
            },
            'agreement': manual_class == ml_result.get('predicted_class', 'unknown')
        }
        
        results.append(result)
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        print(f"   üë®‚Äçüåæ –†—É—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: {manual_class}")
        print(f"   ü§ñ –ò–ò –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {ml_result.get('predicted_class_ru', '–æ—à–∏–±–∫–∞')} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {ml_result.get('confidence', 0):.2f})")
        
        agreement = "‚úÖ –°–æ–≥–ª–∞—Å–∏–µ" if result['agreement'] else "‚ùå –†–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ"
        print(f"   {agreement}")
        
        if visual_features.get('error'):
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {visual_features['error']}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    results_file = "photo_analysis_results.json"
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {results_file}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ê–ù–ê–õ–ò–ó–ê:")
    print("=" * 40)
    
    # –ü–æ–¥—Å—á–µ—Ç –ø–æ —Ç–∏–ø–∞–º –∫—É–ª—å—Ç—É—Ä (—Ä—É—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞)
    manual_counts = {}
    ml_counts = {}
    agreements = 0
    
    for result in results:
        manual_class = result['manual_identification']['class']
        ml_class = result['ml_prediction']['class']
        
        manual_counts[manual_class] = manual_counts.get(manual_class, 0) + 1
        ml_counts[ml_class] = ml_counts.get(ml_class, 0) + 1
        
        if result['agreement']:
            agreements += 1
    
    print("–†—É—á–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è:")
    for crop, count in manual_counts.items():
        print(f"   {crop}: {count} —Ñ–æ—Ç–æ")
    
    print("\n–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ò–ò:")
    for crop, count in ml_counts.items():
        print(f"   {crop}: {count} —Ñ–æ—Ç–æ")
    
    agreement_rate = agreements / len(results) * 100
    print(f"\n–°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å: {agreements}/{len(results)} ({agreement_rate:.1f}%)")
    
    return results

def create_training_dataset(results):
    """–°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞"""
    print("\nüéØ –°–û–ó–î–ê–ù–ò–ï –î–ê–¢–ê–°–ï–¢–ê –î–õ–Ø –û–ë–£–ß–ï–ù–ò–Ø")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫ –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞
    dataset_dir = Path("data/training_dataset")
    
    for crop in ['wheat', 'corn', 'barley']:
        crop_dir = dataset_dir / crop
        crop_dir.mkdir(parents=True, exist_ok=True)
    
    # –ö–æ–ø–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–∞–ø–∫–∏
    import shutil
    
    copied_files = {'wheat': 0, 'corn': 0, 'barley': 0}
    
    for result in results:
        if result.get('manual_identification', {}).get('confidence', 0) > 0.5:
            manual_class = result['manual_identification']['class']
            source_path = Path(result['file_info']['path'])
            
            if manual_class in ['wheat', 'corn', 'barley']:
                # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
                dest_name = f"{manual_class}_{source_path.stem}_{copied_files[manual_class]:03d}{source_path.suffix}"
                dest_path = dataset_dir / manual_class / dest_name
                
                try:
                    shutil.copy2(source_path, dest_path)
                    copied_files[manual_class] += 1
                    print(f"‚úÖ {source_path.name} ‚Üí {manual_class}/{dest_name}")
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è {source_path.name}: {e}")
    
    print(f"\nüìÅ –î–∞—Ç–∞—Å–µ—Ç —Å–æ–∑–¥–∞–Ω –≤ {dataset_dir}")
    print("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞:")
    for crop, count in copied_files.items():
        print(f"   {crop}: {count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
    metadata = {
        'dataset_info': {
            'name': 'Agro Photo Dataset',
            'description': '–î–∞—Ç–∞—Å–µ—Ç —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π —Å–µ–ª—å—Å–∫–æ—Ö–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∫—É–ª—å—Ç—É—Ä',
            'classes': ['wheat', 'corn', 'barley'],
            'classes_ru': ['–ø—à–µ–Ω–∏—Ü–∞', '–∫—É–∫—É—Ä—É–∑–∞', '—è—á–º–µ–Ω—å'],
            'total_images': sum(copied_files.values()),
            'class_distribution': copied_files
        },
        'analysis_results': results
    }
    
    metadata_file = dataset_dir / "dataset_metadata.json"
    with open(metadata_file, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    
    print(f"üìÑ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {metadata_file}")
    
    return dataset_dir, copied_files

if __name__ == "__main__":
    print("üåæ –ê–ù–ê–õ–ò–ó –§–û–¢–û–ì–†–ê–§–ò–ô –°–ï–õ–¨–°–ö–û–•–û–ó–Ø–ô–°–¢–í–ï–ù–ù–´–• –ö–£–õ–¨–¢–£–†")
    print("üéØ –¶–µ–ª—å: –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ —Ñ–æ—Ç–æ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
    print("=" * 70)
    
    try:
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏
        results = analyze_all_photos()
        
        if results:
            # –°–æ–∑–¥–∞–µ–º –æ–±—É—á–∞—é—â–∏–π –¥–∞—Ç–∞—Å–µ—Ç
            dataset_dir, stats = create_training_dataset(results)
            
            print("\nüéâ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")
            print("‚úÖ –í—Å–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
            print("‚úÖ –î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å–æ–∑–¥–∞–Ω")
            print("‚úÖ –ì–æ—Ç–æ–≤–æ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —ç—Ç–∞–ø—É - –æ–±—É—á–µ–Ω–∏—é –º–æ–¥–µ–ª–∏")
            
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏")
            
    except Exception as e:
        print(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc() 