from fastapi import FastAPI, UploadFile, File, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn
from PIL import Image
import io
from typing import Dict, List, Optional
import logging
import traceback
import numpy as np

from ..config.settings import settings
from ..models.crop_classifier import (
    create_pretrained_crop_classifier, 
    create_enhanced_crop_classifier,
    SmartCropClassifier  # –ù–æ–≤—ã–π —É–º–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
)
from ..models.quality_assessor import create_pretrained_quality_assessor
from ..models.yield_predictor import create_pretrained_yield_predictor
from ..preprocessing.image_processor import ImagePreprocessor
from ..preprocessing.advanced_image_processor import (
    QualityAwarePreprocessor,
    AdvancedImageEnhancer,
    enhance_image_for_neural_network
)
from .schemas import (
    CropClassificationResponse, 
    QualityAssessmentResponse, 
    YieldPredictionResponse,
    ComprehensiveAnalysisResponse,
    ErrorResponse
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –°–æ–∑–¥–∞–Ω–∏–µ FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
app = FastAPI(
    title=settings.PROJECT_NAME,
    version=settings.VERSION,
    description="API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–µ–ª—å—Å–∫–æ—Ö–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∫—É–ª—å—Ç—É—Ä",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ —É–∫–∞–∂–∏—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–æ–º–µ–Ω—ã
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–µ–π
crop_classifier = None
enhanced_crop_classifier = None  # –°—Ç–∞—Ä–∞—è —É–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
smart_crop_classifier = None     # –ù–æ–≤—ã–π —É–º–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
quality_assessor = None
yield_predictor = None
image_processor = None
advanced_processor = None
image_enhancer = None

@app.on_event("startup")
async def startup_event():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ"""
    global crop_classifier, enhanced_crop_classifier, smart_crop_classifier, quality_assessor, yield_predictor, image_processor, advanced_processor, image_enhancer
    
    logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...")
    
    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤–æ–≥–æ —É–º–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ (–≤—ã—Å—à–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
        try:
            logger.info("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–º–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è...")
            smart_crop_classifier = SmartCropClassifier(prefer_advanced=True)
            logger.info("‚úÖ –£–º–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
            logger.info("üéØ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω")
            logger.info("üß† –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –≤–∫–ª—é—á–µ–Ω–∞")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —É–º–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä: {e}")
            smart_crop_classifier = None
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (—Å—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
        try:
            enhanced_crop_classifier = create_enhanced_crop_classifier()
            logger.info("üéØ –£–ª—É—á—à–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
            logger.info("‚úÖ –ê–Ω—Å–∞–º–±–ª–µ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω")
            logger.info("‚úÖ –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –≤–∫–ª—é—á–µ–Ω")
            logger.info("‚úÖ –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –∫—É–∫—É—Ä—É–∑—ã –∞–∫—Ç–∏–≤–Ω–∞")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —É–ª—É—á—à–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å: {e}")
            logger.info("üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –º–æ–¥–µ–ª—å...")
            enhanced_crop_classifier = None
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏ –∫–∞–∫ —Ä–µ–∑–µ—Ä–≤
        crop_classifier = create_pretrained_crop_classifier()
        quality_assessor = create_pretrained_quality_assessor()
        yield_predictor = create_pretrained_yield_predictor()
        image_processor = ImagePreprocessor()
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤
        advanced_processor = QualityAwarePreprocessor()
        image_enhancer = AdvancedImageEnhancer()
        
        logger.info("–ú–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–µ–π: {e}")
        raise

def get_models():
    """Dependency –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π"""
    if not all([crop_classifier, quality_assessor, yield_predictor, image_processor]):
        raise HTTPException(status_code=503, detail="–ú–æ–¥–µ–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
    
    return {
        "crop_classifier": crop_classifier,
        "enhanced_crop_classifier": enhanced_crop_classifier,  # –°—Ç–∞—Ä–∞—è —É–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        "smart_crop_classifier": smart_crop_classifier,        # –ù–æ–≤—ã–π —É–º–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
        "quality_assessor": quality_assessor,
        "yield_predictor": yield_predictor,
        "image_processor": image_processor,
        "advanced_processor": advanced_processor,
        "image_enhancer": image_enhancer
    }

async def validate_and_process_image(file: UploadFile) -> Image.Image:
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
    contents = await file.read()
    if len(contents) > settings.MAX_FILE_SIZE:
        raise HTTPException(
            status_code=400,
            detail=f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {settings.MAX_FILE_SIZE / 1024 / 1024:.1f} MB"
        )
    
    # –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    try:
        image = Image.open(io.BytesIO(contents))
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image.verify()
        # –ü–µ—Ä–µ–æ—Ç–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª, —Ç–∞–∫ –∫–∞–∫ verify() –ø–æ—Ä—Ç–∏—Ç –æ–±—ä–µ–∫—Ç
        image = Image.open(io.BytesIO(contents))
        return image
    except Exception as e:
        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –ø—Ä–æ–≤–µ—Ä—è–µ–º content_type
        if file.content_type and not file.content_type.startswith("image/"):
            raise HTTPException(
                status_code=400, 
                detail="–§–∞–π–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º"
            )
        else:
            raise HTTPException(
                status_code=400,
                detail=f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å —Ñ–∞–π–ª –∫–∞–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {str(e)}"
            )

@app.get("/")
async def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç"""
    return {
        "message": "–ê–≥—Ä–æ–ø–∞–π–ø–ª–∞–π–Ω API",
        "version": settings.VERSION,
        "status": "–∞–∫—Ç–∏–≤–µ–Ω",
        "endpoints": {
            "classify": "/classify - –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∫—É–ª—å—Ç—É—Ä—ã",
            "quality": "/quality - –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞",
            "yield": "/yield - –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Ä–æ–∂–∞–π–Ω–æ—Å—Ç–∏",
            "analyze": "/analyze - –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑",
            "image_quality": "/image/quality - –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è",
            "image_enhance": "/image/enhance - –£–ª—É—á—à–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è",
            "classify_advanced": "/classify/advanced - –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è",
            "analyze_comprehensive": "/analyze/comprehensive - –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å —É–ª—É—á—à–µ–Ω–∏–µ–º"
        }
    }

@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–∏—Å–∞"""
    models_status = {
        "crop_classifier": crop_classifier is not None,
        "enhanced_crop_classifier": enhanced_crop_classifier is not None,
        "smart_crop_classifier": smart_crop_classifier is not None,  # –ù–æ–≤—ã–π —É–º–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
        "quality_assessor": quality_assessor is not None,
        "yield_predictor": yield_predictor is not None,
        "image_processor": image_processor is not None,
        "advanced_processor": advanced_processor is not None,
        "image_enhancer": image_enhancer is not None
    }
    
    all_loaded = all([crop_classifier, quality_assessor, yield_predictor, image_processor])
    enhanced_available = enhanced_crop_classifier is not None
    smart_available = smart_crop_classifier is not None
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∏–ø–µ —É–º–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
    smart_info = {}
    if smart_crop_classifier:
        try:
            smart_info = smart_crop_classifier.get_classifier_info()
        except:
            smart_info = {"type": "unknown"}
    
    return {
        "status": "healthy" if all_loaded else "degraded",
        "models": models_status,
        "device": settings.DEVICE,
        "enhanced_classification": enhanced_available,
        "smart_classification": smart_available,
        "smart_classifier_type": smart_info.get("type", "none"),
        "features": {
            "basic_processing": True,
            "enhanced_crop_classification": enhanced_available,
            "smart_crop_classification": smart_available,
            "next_gen_models": smart_info.get("type") == "NextGen",
            "swin_transformer": smart_info.get("type") == "NextGen",
            "vision_transformer": smart_info.get("type") == "NextGen",
            "efficientnetv2": smart_info.get("type") == "NextGen",
            "morphological_analysis": enhanced_available or smart_available,
            "corn_specialization": enhanced_available or smart_available,
            "ensemble_models": enhanced_available or smart_available,
            "advanced_processing": advanced_processor is not None,
            "image_enhancement": image_enhancer is not None,
            "quality_assessment": True,
            "multi_scale_features": True,
            "attention_maps": True
        }
    }

@app.post("/classify", response_model=CropClassificationResponse)
async def classify_crop(
    file: UploadFile = File(...),
    models: Dict = Depends(get_models)
):
    """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–µ–ª—å—Å–∫–æ—Ö–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω–æ–π –∫—É–ª—å—Ç—É—Ä—ã —Å —É–º–Ω—ã–º –≤—ã–±–æ—Ä–æ–º –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏"""
    try:
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image = await validate_and_process_image(file)
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        processed = models["image_processor"].preprocess_image(image)
        if not processed["is_valid"]:
            raise HTTPException(
                status_code=400,
                detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {processed['errors']}"
            )
        
        # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π –¥–æ—Å—Ç—É–ø–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: —É–º–Ω—ã–π -> —É–ª—É—á—à–µ–Ω–Ω—ã–π -> —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π)
        if models.get("smart_crop_classifier"):
            logger.info("üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ–º –£–ú–ù–´–ô –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –≤—ã–±–æ—Ä–æ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã")
            result = models["smart_crop_classifier"].predict(processed["processed_image"])
        elif models.get("enhanced_crop_classifier"):
            logger.info("üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å —Å –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–º –∞–Ω–∞–ª–∏–∑–æ–º")
            result = models["enhanced_crop_classifier"].predict(processed["processed_image"])
        else:
            logger.info("‚öôÔ∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –º–æ–¥–µ–ª—å")
            result = models["crop_classifier"].predict(processed["processed_image"])
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º numpy —Ç–∏–ø—ã
        result = convert_numpy_types(result)
        
        return CropClassificationResponse(
            success=True,
            predicted_class=result["predicted_class"],
            predicted_class_ru=result["predicted_class_ru"],
            confidence=result["confidence"],
            confidence_level=result.get("confidence_level", "–°—Ä–µ–¥–Ω—è—è"),
            probabilities=result["probabilities"],
            probabilities_ru=result["probabilities_ru"],
            is_confident=result.get("is_confident", True),
            analysis_notes=result.get("analysis_notes", []),
            processing_info={
                "original_size": processed["original_size"],
                "final_size": processed["final_size"],
                "warnings": processed["warnings"],
                "is_valid": processed["is_valid"],
                "classifier_used": result.get("classifier_type", "unknown")  # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∏–ø–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
            },
            corn_analysis=result.get("corn_analysis", {}),  # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∫—É–∫—É—Ä—É–∑—ã
            morphology_analysis=result.get("morphology_analysis", {}),  # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
            model_results=result.get("model_results", {})  # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}")

@app.post("/quality", response_model=QualityAssessmentResponse)
async def assess_quality(
    file: UploadFile = File(...),
    models: Dict = Depends(get_models)
):
    """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–µ–ª—å—Å–∫–æ—Ö–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω–æ–π –∫—É–ª—å—Ç—É—Ä—ã"""
    try:
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image = await validate_and_process_image(file)
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        processed = models["image_processor"].preprocess_image(image)
        if not processed["is_valid"]:
            raise HTTPException(
                status_code=400,
                detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {processed['errors']}"
            )
        
        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        result = models["quality_assessor"].predict(processed["processed_image"])
        
        return QualityAssessmentResponse(
            success=True,
            quality=result["quality"],
            disease=result["disease"],
            maturity=result["maturity"],
            overall_score=result["overall_score"],
            overall_quality=result["overall_quality"],
            is_healthy=result["is_healthy"],
            health_status=result.get("health_status"),
            health_analysis=result.get("health_analysis"),
            recommendations=result["recommendations"],
            processing_info={
                "original_size": processed["original_size"],
                "final_size": processed["final_size"],
                "warnings": processed["warnings"]
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}")

@app.post("/yield", response_model=YieldPredictionResponse)
async def predict_yield(
    file: UploadFile = File(...),
    models: Dict = Depends(get_models)
):
    """–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Ä–æ–∂–∞–π–Ω–æ—Å—Ç–∏"""
    try:
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image = await validate_and_process_image(file)
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        processed = models["image_processor"].preprocess_image(image)
        if not processed["is_valid"]:
            raise HTTPException(
                status_code=400,
                detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {processed['errors']}"
            )
        
        # –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Ä–æ–∂–∞–π–Ω–æ—Å—Ç–∏
        result = models["yield_predictor"].predict_yield(processed["processed_image"])
        
        return YieldPredictionResponse(
            success=True,
            predicted_yield_tons_per_ha=result["predicted_yield_tons_per_ha"],
            confidence=result["confidence"],
            prediction_range=result["prediction_range"],
            individual_predictions=result["individual_predictions"],
            recommendations=result["recommendations"],
            processing_info={
                "original_size": processed["original_size"],
                "final_size": processed["final_size"],
                "warnings": processed["warnings"]
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —É—Ä–æ–∂–∞–π–Ω–æ—Å—Ç–∏: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}")

@app.post("/analyze", response_model=ComprehensiveAnalysisResponse)
async def comprehensive_analysis(
    file: UploadFile = File(...),
    models: Dict = Depends(get_models)
):
    """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–µ–ª—å—Å–∫–æ—Ö–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω–æ–π –∫—É–ª—å—Ç—É—Ä—ã"""
    try:
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image = await validate_and_process_image(file)
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        processed = models["image_processor"].preprocess_image(image)
        if not processed["is_valid"]:
            raise HTTPException(
                status_code=400,
                detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {processed['errors']}"
            )
        
        processed_image = processed["processed_image"]
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –∞–Ω–∞–ª–∏–∑—ã - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç—É –∂–µ –ª–æ–≥–∏–∫—É –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏, —á—Ç–æ –∏ –≤ /classify
        if models.get("enhanced_crop_classifier"):
            logger.info("üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
            crop_result = models["enhanced_crop_classifier"].predict(processed_image)
        else:
            logger.info("‚öôÔ∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
            crop_result = models["crop_classifier"].predict(processed_image)
            
        quality_result = models["quality_assessor"].predict(processed_image)
        yield_result = models["yield_predictor"].predict_yield(processed_image)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º numpy —Ç–∏–ø—ã –≤ –æ–±—ã—á–Ω—ã–µ Python —Ç–∏–ø—ã
        crop_result = convert_numpy_types(crop_result)
        quality_result = convert_numpy_types(quality_result)
        yield_result = convert_numpy_types(yield_result)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        comprehensive_recommendations = _generate_comprehensive_recommendations(
            crop_result, quality_result, yield_result
        )
        
        return ComprehensiveAnalysisResponse(
            success=True,
            crop_classification=crop_result,
            quality_assessment=quality_result,
            yield_prediction=yield_result,
            comprehensive_recommendations=comprehensive_recommendations,
            processing_info={
                "original_size": processed["original_size"],
                "final_size": processed["final_size"],
                "warnings": processed["warnings"]
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}")

def _generate_comprehensive_recommendations(crop_result: Dict, quality_result: Dict, yield_result: Dict) -> List[str]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
    recommendations = []
    
    # –ê–Ω–∞–ª–∏–∑ –∫—É–ª—å—Ç—É—Ä—ã
    crop_class = crop_result["predicted_class_ru"]
    if not crop_result["is_confident"]:
        recommendations.append(f"–ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –∫—É–ª—å—Ç—É—Ä—ã ({crop_class}). –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞.")
    
    # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞
    if not quality_result["is_healthy"]:
        disease = quality_result["disease"]["predicted_class_ru"]
        recommendations.append(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–µ: {disease}. –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –ª–µ—á–µ–Ω–∏–µ.")
    
    overall_score = quality_result["overall_score"]
    if overall_score < 3.0:
        recommendations.append("–û–±—â–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∫—É–ª—å—Ç—É—Ä—ã –Ω–∏–∑–∫–æ–µ. –¢—Ä–µ–±—É–µ—Ç—Å—è –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —É–ª—É—á—à–µ–Ω–∏—é —É—Å–ª–æ–≤–∏–π.")
    
    # –ê–Ω–∞–ª–∏–∑ —É—Ä–æ–∂–∞–π–Ω–æ—Å—Ç–∏
    predicted_yield = yield_result["predicted_yield_tons_per_ha"]
    yield_confidence = yield_result["confidence"]
    
    if predicted_yield < 3.0:
        recommendations.append("–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º–∞—è —É—Ä–æ–∂–∞–π–Ω–æ—Å—Ç—å –Ω–∏–∑–∫–∞—è. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∞–Ω–∞–ª–∏–∑ –∏ —É–ª—É—á—à–µ–Ω–∏–µ –∞–≥—Ä–æ—Ç–µ—Ö–Ω–∏–∫–∏.")
    elif predicted_yield > 7.0:
        recommendations.append("–í—ã—Å–æ–∫–∞—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º–∞—è —É—Ä–æ–∂–∞–π–Ω–æ—Å—Ç—å. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π—Ç–µ —Ç–µ–∫—É—â–∏–µ —É—Å–ª–æ–≤–∏—è –≤—ã—Ä–∞—â–∏–≤–∞–Ω–∏—è.")
    
    if yield_confidence < 0.7:
        recommendations.append("–ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø—Ä–æ–≥–Ω–æ–∑–µ —É—Ä–æ–∂–∞–π–Ω–æ—Å—Ç–∏. –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥.")
    
    # –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    if overall_score > 3.5 and predicted_yield > 5.0 and quality_result["is_healthy"]:
        recommendations.append("–ö—É–ª—å—Ç—É—Ä–∞ –≤ –æ—Ç–ª–∏—á–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏! –ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ —Ç–µ–∫—É—â–∏–π —É—Ö–æ–¥.")
    
    return recommendations

@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    """–ì–ª–æ–±–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –∏—Å–∫–ª—é—á–µ–Ω–∏–π"""
    logger.error(f"–ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {exc}")
    logger.error(traceback.format_exc())
    
    return JSONResponse(
        status_code=500,
        content={
            "success": False,
            "error": "–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞",
            "detail": str(exc) if settings.DEBUG else "–û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É"
        }
    )

def convert_numpy_types(obj):
    """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç numpy —Ç–∏–ø—ã –≤ –æ–±—ã—á–Ω—ã–µ Python —Ç–∏–ø—ã"""
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.bool_):
        return bool(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [convert_numpy_types(item) for item in obj]
    else:
        return obj

@app.post("/image/quality")
async def assess_image_quality(
    file: UploadFile = File(...),
    models: Dict = Depends(get_models)
):
    """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    import time
    
    try:
        start_time = time.time()
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image = await validate_and_process_image(file)
        
        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        quality_info = models["advanced_processor"].assess_image_quality(image)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ª–∏ —É–ª—É—á—à–µ–Ω–∏–µ
        enhancement_recommended = quality_info["quality_score"] < 0.7
        
        processing_time = time.time() - start_time
        
        return {
            "success": True,
            "quality_metrics": quality_info,
            "enhancement_recommended": enhancement_recommended,
            "processing_time": processing_time
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}")

@app.post("/image/enhance")
async def enhance_image(
    file: UploadFile = File(...),
    models: Dict = Depends(get_models)
):
    """–£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    import time
    import base64
    from io import BytesIO
    
    try:
        start_time = time.time()
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image = await validate_and_process_image(file)
        
        # –û—Ü–µ–Ω–∫–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
        original_quality = models["advanced_processor"].assess_image_quality(image)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å —É–ª—É—á—à–µ–Ω–∏—è
        enhancement_needed = original_quality["quality_score"] < 0.7
        
        enhanced_quality = None
        improvement_achieved = None
        enhanced_image_b64 = None
        
        if enhancement_needed:
            # –£–ª—É—á—à–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            enhanced_image = models["image_enhancer"].enhance_for_recognition(image)
            
            # –û—Ü–µ–Ω–∫–∞ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
            enhanced_quality = models["advanced_processor"].assess_image_quality(enhanced_image)
            improvement_achieved = enhanced_quality["quality_score"] - original_quality["quality_score"]
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —É–ª—É—á—à–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ base64 –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞
            buffered = BytesIO()
            enhanced_image.save(buffered, format="JPEG", quality=95)
            enhanced_image_b64 = base64.b64encode(buffered.getvalue()).decode()
        
        processing_time = time.time() - start_time
        
        return {
            "success": True,
            "enhancement_applied": enhancement_needed,
            "original_quality": original_quality,
            "enhanced_quality": enhanced_quality,
            "improvement_achieved": improvement_achieved,
            "processing_time": processing_time,
            "enhanced_image_base64": enhanced_image_b64
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —É–ª—É—á—à–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}")

@app.post("/classify/advanced")
async def advanced_classify_crop(
    file: UploadFile = File(...),
    use_multi_scale: bool = True,
    use_attention: bool = True,
    models: Dict = Depends(get_models)
):
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    try:
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image = await validate_and_process_image(file)
        
        # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        result = enhance_image_for_neural_network(
            image,
            target_size=settings.IMAGE_SIZE,
            include_multi_scale=use_multi_scale,
            include_attention=use_attention
        )
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å –æ—Å–Ω–æ–≤–Ω—ã–º —Ç–µ–Ω–∑–æ—Ä–æ–º
        classification_result = models["crop_classifier"].predict_tensor(result["tensor"])
        
        # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –æ–±—Ä–∞–±–æ—Ç–∫–µ
        processing_info = {
            "original_size": result["original_image"].size,
            "final_size": result["enhanced_image"].size,
            "enhancement_applied": result["enhancement_applied"],
            "quality_metrics": result["quality_info"],
            "multi_scale_available": use_multi_scale,
            "attention_maps_available": use_attention
        }
        
        return {
            "success": True,
            "predicted_class": classification_result["predicted_class"],
            "predicted_class_ru": classification_result["predicted_class_ru"],
            "confidence": classification_result["confidence"],
            "confidence_level": classification_result.get("confidence_level"),
            "confidence_gap": classification_result.get("confidence_gap"),
            "probabilities": classification_result["probabilities"],
            "probabilities_ru": classification_result["probabilities_ru"],
            "is_confident": classification_result["is_confident"],
            "analysis_notes": classification_result.get("analysis_notes"),
            "processing_info": processing_info
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}")

@app.post("/analyze/comprehensive")
async def comprehensive_enhanced_analysis(
    file: UploadFile = File(...),
    use_enhancement: bool = True,
    models: Dict = Depends(get_models)
):
    """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    try:
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image = await validate_and_process_image(file)
        
        if use_enhancement:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
            enhanced_result = models["advanced_processor"].adaptive_preprocess(image)
            processed_image = enhanced_result["enhanced_image"]
            processing_info = {
                "original_size": enhanced_result["original_image"].size,
                "final_size": enhanced_result["enhanced_image"].size,
                "enhancement_applied": enhanced_result["enhancement_applied"],
                "quality_metrics": enhanced_result["quality_info"],
                "warnings": []
            }
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
            processed = models["image_processor"].preprocess_image(image)
            if not processed["is_valid"]:
                raise HTTPException(
                    status_code=400,
                    detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {processed['errors']}"
                )
            processed_image = processed["processed_image"]
            processing_info = {
                "original_size": processed["original_size"],
                "final_size": processed["final_size"],
                "enhancement_applied": False,
                "quality_metrics": None,
                "warnings": processed["warnings"]
            }
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –∞–Ω–∞–ª–∏–∑—ã
        crop_result = models["crop_classifier"].predict(processed_image)
        quality_result = models["quality_assessor"].predict(processed_image)
        yield_result = models["yield_predictor"].predict_yield(processed_image)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º numpy —Ç–∏–ø—ã
        crop_result = convert_numpy_types(crop_result)
        quality_result = convert_numpy_types(quality_result)
        yield_result = convert_numpy_types(yield_result)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        comprehensive_recommendations = _generate_enhanced_recommendations(
            crop_result, quality_result, yield_result, processing_info
        )
        
        return {
            "success": True,
            "crop_classification": crop_result,
            "quality_assessment": quality_result,
            "yield_prediction": yield_result,
            "comprehensive_recommendations": comprehensive_recommendations,
            "processing_info": processing_info
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}")

def _generate_enhanced_recommendations(crop_result: Dict, quality_result: Dict, 
                                     yield_result: Dict, processing_info: Dict) -> List[str]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —Å —É—á–µ—Ç–æ–º –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    recommendations = []
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    if processing_info.get("quality_metrics"):
        quality_metrics = processing_info["quality_metrics"]
        if quality_metrics["quality_score"] < 0.5:
            recommendations.append("–ö–∞—á–µ—Å—Ç–≤–æ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∏–∑–∫–æ–µ. –î–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞.")
        
        if quality_metrics.get("improvement") and quality_metrics["improvement"] > 0.1:
            recommendations.append(f"–ö–∞—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —É–ª—É—á—à–µ–Ω–æ –Ω–∞ {quality_metrics['improvement']:.1%}. –≠—Ç–æ –ø–æ–≤—ã—Å–∏–ª–æ —Ç–æ—á–Ω–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞.")
    
    # –ë–∞–∑–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    base_recommendations = _generate_comprehensive_recommendations(crop_result, quality_result, yield_result)
    recommendations.extend(base_recommendations)
    
    return recommendations

@app.post("/classify/nextgen")
async def classify_crop_nextgen(
    file: UploadFile = File(...),
    models: Dict = Depends(get_models)
):
    """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è"""
    try:
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image = await validate_and_process_image(file)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —É–º–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
        if not models.get("smart_crop_classifier"):
            raise HTTPException(
                status_code=503,
                detail="–£–º–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
            )
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        processed = models["image_processor"].preprocess_image(image)
        if not processed["is_valid"]:
            raise HTTPException(
                status_code=400,
                detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {processed['errors']}"
            )
        
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –ù–û–í–û–ì–û –ü–û–ö–û–õ–ï–ù–ò–Ø")
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–µ
        classifier_info = models["smart_crop_classifier"].get_classifier_info()
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é
        result = models["smart_crop_classifier"].predict(processed["processed_image"])
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º numpy —Ç–∏–ø—ã
        result = convert_numpy_types(result)
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        return {
            "success": True,
            "classifier_info": {
                "type": classifier_info.get("type", "unknown"),
                "description": classifier_info.get("description", ""),
                "available_advanced": classifier_info.get("available_advanced", False),
                "device": classifier_info.get("device", "unknown")
            },
            "prediction": {
                "predicted_class": result["predicted_class"],
                "predicted_class_ru": result["predicted_class_ru"],
                "confidence": result["confidence"],
                "confidence_level": result.get("confidence_level", "–°—Ä–µ–¥–Ω—è—è"),
                "probabilities": result["probabilities"],
                "probabilities_ru": result["probabilities_ru"],
                "is_confident": result.get("is_confident", True)
            },
            "analysis": {
                "notes": result.get("analysis_notes", []),
                "morphology": result.get("morphology_analysis", {}),
                "model_results": result.get("model_results", {}),
                "ensemble_method": result.get("ensemble_method", "unknown")
            },
            "processing_info": {
                "original_size": processed["original_size"],
                "final_size": processed["final_size"],
                "warnings": processed["warnings"],
                "is_valid": processed["is_valid"]
            },
            "features_used": {
                "modern_architectures": classifier_info.get("type") == "NextGen",
                "swin_transformer": classifier_info.get("type") == "NextGen",
                "vision_transformer": classifier_info.get("type") == "NextGen",
                "efficientnetv2": classifier_info.get("type") == "NextGen",
                "morphological_analysis": "morphology_analysis" in result,
                "ensemble_voting": "model_results" in result,
                "intelligent_correction": "–ö–û–†–†–ï–ö–¶–ò–Ø" in str(result.get("analysis_notes", []))
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–µ –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è: {e}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}")

@app.get("/models/info")
async def get_models_info(models: Dict = Depends(get_models)):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö"""
    
    info = {
        "available_models": {
            "standard_classifier": models.get("crop_classifier") is not None,
            "enhanced_classifier": models.get("enhanced_crop_classifier") is not None,
            "smart_classifier": models.get("smart_crop_classifier") is not None,
            "quality_assessor": models.get("quality_assessor") is not None,
            "yield_predictor": models.get("yield_predictor") is not None
        },
        "smart_classifier_info": {},
        "capabilities": {
            "basic_classification": True,
            "enhanced_classification": False,
            "next_gen_classification": False,
            "morphological_analysis": False,
            "ensemble_models": False,
            "modern_architectures": False
        }
    }
    
    # –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± —É–º–Ω–æ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–µ
    if models.get("smart_crop_classifier"):
        try:
            smart_info = models["smart_crop_classifier"].get_classifier_info()
            info["smart_classifier_info"] = smart_info
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
            info["capabilities"]["next_gen_classification"] = True
            info["capabilities"]["morphological_analysis"] = True
            info["capabilities"]["ensemble_models"] = True
            
            if smart_info.get("type") == "NextGen":
                info["capabilities"]["modern_architectures"] = True
                info["capabilities"]["swin_transformer"] = True
                info["capabilities"]["vision_transformer"] = True
                info["capabilities"]["efficientnetv2"] = True
                
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± —É–º–Ω–æ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–µ: {e}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
    if models.get("enhanced_crop_classifier"):
        info["capabilities"]["enhanced_classification"] = True
        if not info["capabilities"]["morphological_analysis"]:
            info["capabilities"]["morphological_analysis"] = True
        if not info["capabilities"]["ensemble_models"]:
            info["capabilities"]["ensemble_models"] = True
    
    return info

if __name__ == "__main__":
    uvicorn.run(
        app, 
        host=settings.API_HOST, 
        port=settings.API_PORT,
        reload=settings.DEBUG
    ) 