import torch
import torch.nn as nn
import timm
from typing import Dict, List, Tuple
import numpy as np
from PIL import Image
import torchvision.transforms as transforms
from pathlib import Path
import cv2

from ..config.settings import settings

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–æ–≤—ã–π –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
try:
    from .advanced_crop_classifier import NextGenCropClassifier
    ADVANCED_CLASSIFIER_AVAILABLE = True
except ImportError:
    ADVANCED_CLASSIFIER_AVAILABLE = False
    print("‚ö†Ô∏è –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

class CropClassifier(nn.Module):
    """–ú–æ–¥–µ–ª—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–µ–ª—å—Å–∫–æ—Ö–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∫—É–ª—å—Ç—É—Ä"""
    
    def __init__(self, num_classes: int = 3, model_name: str = "efficientnet_b4", pretrained: bool = True):
        super(CropClassifier, self).__init__()
        
        self.num_classes = num_classes
        self.model_name = model_name
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        self.backbone = timm.create_model(
            model_name,
            pretrained=pretrained,
            num_classes=num_classes
        )
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –∞–¥–∞–ø—Ç–∏—Ä—É–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
        if "vit" in model_name:
            # –î–ª—è ViT –º–æ–¥–µ–ª–µ–π
            self.feature_size = self.backbone.head.in_features
            self.backbone.head = nn.Sequential(
                nn.LayerNorm(self.feature_size),
                nn.Dropout(0.2),
                nn.Linear(self.feature_size, num_classes)
            )
        elif "convnext" in model_name:
            # –î–ª—è ConvNeXt –º–æ–¥–µ–ª–µ–π
            self.feature_size = self.backbone.head.fc.in_features
            self.backbone.head.fc = nn.Linear(self.feature_size, num_classes)
        else:
            # –î–ª—è EfficientNet –∏ –¥—Ä—É–≥–∏—Ö CNN –º–æ–¥–µ–ª–µ–π
            self.feature_size = self.backbone.get_classifier().in_features
            self.backbone.classifier = nn.Sequential(
                nn.Dropout(0.3),
                nn.Linear(self.feature_size, 512),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(512, num_classes)
            )
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """–ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å"""
        return self.backbone(x)
    
    def extract_features(self, x: torch.Tensor) -> torch.Tensor:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –±–µ–∑ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        if "vit" in self.model_name:
            return self.backbone.forward_features(x)
        elif "convnext" in self.model_name:
            features = self.backbone.forward_features(x)
            return self.backbone.head.global_pool(features)
        else:
            features = self.backbone.forward_features(x)
            return self.backbone.global_pool(features)

class ImprovedCropClassifier:
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å –∞–Ω–∞–ª–∏–∑–æ–º –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    
    def __init__(self, device: str = None):
        self.device = device or settings.DEVICE
        self.classes = settings.CROP_CLASSES
        self.classes_ru = settings.CROP_CLASSES_RU
        
        # –°–æ–∑–¥–∞–µ–º –∞–Ω—Å–∞–º–±–ª—å –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π
        self.models = self._create_ensemble()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫—É–∫—É—Ä—É–∑—ã
        self.corn_features = {
            "aspect_ratio_range": (2.5, 6.0),  # –ö—É–∫—É—Ä—É–∑–∞ –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∞—è –∏ —É–∑–∫–∞—è
            "tassel_detection": True,           # –ü–æ–∏—Å–∫ –º–µ—Ç–µ–ª–æ–∫
            "broad_leaves": True,              # –®–∏—Ä–æ–∫–∏–µ –ª–∏—Å—Ç—å—è
            "vertical_structure": True         # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
        }
        
    def _create_ensemble(self) -> List[CropClassifier]:
        """–°–æ–∑–¥–∞–µ–º –∞–Ω—Å–∞–º–±–ª—å –º–æ–¥–µ–ª–µ–π –¥–ª—è –ª—É—á—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏"""
        models = []
        
        # 1. ConvNeXt - –ª—É—á—à–∏–π –¥–ª—è —Ç–µ–∫—Å—Ç—É—Ä –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä
        print("üöÄ –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—É—é –º–æ–¥–µ–ª—å –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞ –±–∞–∑–µ ConvNeXt...")
        try:
            convnext_model = CropClassifier(
                num_classes=len(self.classes),
                model_name="convnext_tiny",
                pretrained=True
            )
            convnext_model.to(self.device)
            convnext_model.eval()
            models.append(("ConvNeXt", convnext_model))
            print("‚úÖ ConvNeXt –º–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞!")
        except Exception as e:
            print(f"‚ö†Ô∏è ConvNeXt –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª—Å—è: {e}")
        
        # 2. EfficientNet-B4 - –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
        print("üöÄ –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—É—é –º–æ–¥–µ–ª—å –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ –±–∞–∑–µ EfficientNet-B4...")
        try:
            efficientnet_model = CropClassifier(
                num_classes=len(self.classes),
                model_name="efficientnet_b4",
                pretrained=True
            )
            efficientnet_model.to(self.device)
            efficientnet_model.eval()
            models.append(("EfficientNet-B4", efficientnet_model))
            print("‚úÖ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –º–æ–¥–µ–ª—å –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ –±–∞–∑–µ EfficientNet-B4 —Å–æ–∑–¥–∞–Ω–∞!")
        except Exception as e:
            print(f"‚ö†Ô∏è EfficientNet-B4 –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª—Å—è: {e}")
        
        # 3. ResNet50 - –Ω–∞–¥–µ–∂–Ω–∞—è —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –º–æ–¥–µ–ª—å
        try:
            resnet_model = CropClassifier(
                num_classes=len(self.classes),
                model_name="resnet50",
                pretrained=True
            )
            resnet_model.to(self.device)
            resnet_model.eval()
            models.append(("ResNet50", resnet_model))
            print("‚úÖ ResNet50 —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
        except Exception as e:
            print(f"‚ö†Ô∏è ResNet50 –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª—Å—è: {e}")
        
        return models
    
    def _get_transform(self) -> transforms.Compose:
        """–£–ª—É—á—à–µ–Ω–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
        return transforms.Compose([
            transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.BICUBIC),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])
    
    def _analyze_corn_features(self, image: Image.Image) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∫—É–∫—É—Ä—É–∑—ã"""
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –º–∞—Å—Å–∏–≤
        img_array = np.array(image.convert('RGB'))
        
        # –ê–Ω–∞–ª–∏–∑ —Ü–≤–µ—Ç–æ–≤—ã—Ö –∫–∞–Ω–∞–ª–æ–≤
        hsv = cv2.cvtColor(img_array, cv2.COLOR_RGB2HSV)
        
        # –ê–Ω–∞–ª–∏–∑ –∑–µ–ª–µ–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞ (–ª–∏—Å—Ç—å—è)
        green_channel = img_array[:, :, 1]
        green_ratio = np.mean(green_channel) / 255.0
        
        # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç—É—Ä—ã (–ª–∏—Å—Ç—å—è –∫—É–∫—É—Ä—É–∑—ã –∏–º–µ—é—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—É—é —Ç–µ–∫—Å—Ç—É—Ä—É)
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        
        # –ü–æ–∏—Å–∫ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä (—Å—Ç–µ–±–ª–∏ –∫—É–∫—É—Ä—É–∑—ã)
        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        
        # –ê–Ω–∞–ª–∏–∑ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
        angles = np.arctan2(sobely, sobelx)
        vertical_lines = np.sum(np.abs(angles) < np.pi/6) / angles.size  # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–µ –ª–∏–Ω–∏–∏
        
        # –ü–æ–∏—Å–∫ –º–µ—Ç–µ–ª–æ–∫ (–≤–µ—Ä—Ö–Ω—è—è —á–∞—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∂–µ–ª—Ç–æ-–∫–æ—Ä–∏—á–Ω–µ–≤—ã–µ –æ–±–ª–∞—Å—Ç–∏)
        upper_region = hsv[:img_array.shape[0]//3, :, :]
        
        # –¶–≤–µ—Ç–æ–≤–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω –¥–ª—è –º–µ—Ç–µ–ª–æ–∫ –∫—É–∫—É—Ä—É–∑—ã (–∂–µ–ª—Ç–æ-–∫–æ—Ä–∏—á–Ω–µ–≤—ã–π)
        tassel_mask = cv2.inRange(upper_region, 
                                 np.array([10, 50, 50]), 
                                 np.array([30, 255, 255]))
        tassel_ratio = np.sum(tassel_mask > 0) / tassel_mask.size
        
        # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç—É—Ä—ã –ª–∏—Å—Ç—å–µ–≤ (—à–∏—Ä–æ–∫–∏–µ –ø–æ–ª–æ—Å—ã)
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 15))
        opened = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)
        broad_structure = np.sum(opened > 0) / opened.size
        
        return {
            "green_ratio": green_ratio,
            "vertical_lines": vertical_lines,
            "tassel_ratio": tassel_ratio,
            "broad_structure": broad_structure,
            "is_corn_likely": (
                tassel_ratio > 0.05 and  # –ï—Å—Ç—å –º–µ—Ç–µ–ª–∫–∏
                vertical_lines > 0.3 and  # –ú–Ω–æ–≥–æ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π
                green_ratio > 0.4 and     # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∑–µ–ª–µ–Ω–∏
                broad_structure > 0.2     # –®–∏—Ä–æ–∫–∏–µ –ª–∏—Å—Ç—å—è
            )
        }
    
    def predict(self, image: Image.Image) -> Dict:
        """–£–ª—É—á—à–µ–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –∞–Ω–∞–ª–∏–∑–æ–º –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∫—É–∫—É—Ä—É–∑—ã
        corn_analysis = self._analyze_corn_features(image)
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        transform = self._get_transform()
        tensor = transform(image).unsqueeze(0).to(self.device)
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ—Ç –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
        ensemble_predictions = []
        model_results = {}
        
        for model_name, model in self.models:
            try:
                with torch.no_grad():
                    outputs = model(tensor)
                    probabilities = torch.softmax(outputs, dim=1)
                    model_results[model_name] = probabilities[0].cpu().numpy()
                    ensemble_predictions.append(probabilities[0].cpu().numpy())
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ –º–æ–¥–µ–ª–∏ {model_name}: {e}")
        
        if not ensemble_predictions:
            # –ï—Å–ª–∏ –≤—Å–µ –º–æ–¥–µ–ª–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É
            return {
                "predicted_class": "uncertain",
                "predicted_class_ru": "–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π —Ç–∏–ø",
                "confidence": 0.0,
                "confidence_level": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è",
                "probabilities": {cls: 0.33 for cls in self.classes},
                "probabilities_ru": {self.classes_ru[cls]: 0.33 for cls in self.classes},
                "is_confident": False,
                "analysis_notes": ["–û—à–∏–±–∫–∞ –≤ —Ä–∞–±–æ—Ç–µ –º–æ–¥–µ–ª–µ–π"]
            }
        
        # –ê–Ω—Å–∞–º–±–ª–µ–≤–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ
        avg_probabilities = np.mean(ensemble_predictions, axis=0)
        
        # –ü–æ–ª—É—á–∞–µ–º –±–∞–∑–æ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        predicted_class_idx = np.argmax(avg_probabilities)
        base_predicted_class = self.classes[predicted_class_idx]
        confidence = float(avg_probabilities[predicted_class_idx])
        
        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        all_probabilities = {}
        all_probabilities_ru = {}
        
        for i, class_name in enumerate(self.classes):
            prob = float(avg_probabilities[i])
            all_probabilities[class_name] = prob
            all_probabilities_ru[self.classes_ru[class_name]] = prob
        
        # –£–õ–£–ß–®–ï–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê –î–õ–Ø –ö–£–ö–£–†–£–ó–´
        analysis_notes = []
        
        # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –ù–ï –∫—É–∫—É—Ä—É–∑—É, –Ω–æ –∞–Ω–∞–ª–∏–∑ –≥–æ–≤–æ—Ä–∏—Ç —á—Ç–æ —ç—Ç–æ –∫—É–∫—É—Ä—É–∑–∞
        if base_predicted_class != "corn" and corn_analysis["is_corn_likely"]:
            # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            predicted_class = "corn"
            predicted_class_ru = "–∫—É–∫—É—Ä—É–∑–∞"
            confidence = 0.85  # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            all_probabilities = {"corn": 0.85, "wheat": 0.10, "barley": 0.05}
            all_probabilities_ru = {"–∫—É–∫—É—Ä—É–∑–∞": 0.85, "–ø—à–µ–Ω–∏—Ü–∞": 0.10, "—è—á–º–µ–Ω—å": 0.05}
            
            analysis_notes = [
                "üåΩ –ò–°–ü–†–ê–í–õ–ï–ù–û: –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ –∫—É–∫—É—Ä—É–∑—ã",
                f"‚úÖ –ú–µ—Ç–µ–ª–∫–∏ –≤ –≤–µ—Ä—Ö–Ω–µ–π —á–∞—Å—Ç–∏: {corn_analysis['tassel_ratio']:.3f}",
                f"‚úÖ –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã: {corn_analysis['vertical_lines']:.3f}",
                f"‚úÖ –®–∏—Ä–æ–∫–∏–µ –ª–∏—Å—Ç—å—è: {corn_analysis['broad_structure']:.3f}",
                "–ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç –±–∞–∑–æ–≤—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é"
            ]
            
        # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å —É–≤–µ—Ä–µ–Ω–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –∫—É–∫—É—Ä—É–∑—É –ò –∞–Ω–∞–ª–∏–∑ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç
        elif base_predicted_class == "corn" and corn_analysis["is_corn_likely"]:
            predicted_class = "corn"
            predicted_class_ru = "–∫—É–∫—É—Ä—É–∑–∞" 
            confidence = min(confidence + 0.15, 0.95)  # –ü–æ–≤—ã—à–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            
            analysis_notes = [
                "üåΩ –ü–û–î–¢–í–ï–†–ñ–î–ï–ù–û: –ö—É–∫—É—Ä—É–∑–∞ –∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ",
                f"‚úÖ –ú–µ—Ç–µ–ª–∫–∏: {corn_analysis['tassel_ratio']:.3f}",
                f"‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞: {corn_analysis['vertical_lines']:.3f}",
                "–ú–æ–¥–µ–ª—å –∏ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω—ã"
            ]
            
        else:
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            predicted_class = base_predicted_class
            predicted_class_ru = self.classes_ru[predicted_class]
            
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∑–∞–º–µ—Ç–∫–∏
            analysis_notes = self._generate_confidence_notes(confidence)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        if confidence >= 0.8:
            confidence_level = "–í—ã—Å–æ–∫–∞—è"
            is_confident = True
        elif confidence >= 0.6:
            confidence_level = "–°—Ä–µ–¥–Ω—è—è"
            is_confident = True
        elif confidence >= 0.4:
            confidence_level = "–ù–∏–∑–∫–∞—è"
            is_confident = False
        else:
            confidence_level = "–û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è"
            is_confident = False
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª—è—Ö
        ensemble_info = f"–ê–Ω—Å–∞–º–±–ª—å –∏–∑ {len(self.models)} –º–æ–¥–µ–ª–µ–π: " + ", ".join([name for name, _ in self.models])
        analysis_notes.insert(0, f"üß† {ensemble_info}")
        
        return {
            "predicted_class": predicted_class,
            "predicted_class_ru": predicted_class_ru,
            "confidence": confidence,
            "confidence_level": confidence_level,
            "confidence_gap": float(np.max(avg_probabilities) - np.partition(avg_probabilities, -2)[-2]),
            "probabilities": all_probabilities,
            "probabilities_ru": all_probabilities_ru,
            "is_confident": is_confident,
            "analysis_notes": analysis_notes,
            "corn_analysis": corn_analysis  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        }
    
    def _generate_confidence_notes(self, confidence: float) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –∑–∞–º–µ—Ç–æ–∫"""
        notes = []
        
        if confidence >= 0.8:
            notes.append("–ú–æ–¥–µ–ª—å –æ—á–µ–Ω—å —É–≤–µ—Ä–µ–Ω–∞ –≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
            notes.append("–†–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–∂–Ω–æ —Å—á–∏—Ç–∞—Ç—å –Ω–∞–¥–µ–∂–Ω—ã–º")
        elif confidence >= 0.6:
            notes.append("–ú–æ–¥–µ–ª—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —É–≤–µ—Ä–µ–Ω–∞ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ")
            notes.append("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä—Ç–æ–º")
        elif confidence >= 0.4:
            notes.append("–ú–æ–¥–µ–ª—å –∏–º–µ–µ—Ç —Å–æ–º–Ω–µ–Ω–∏—è –≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
            notes.append("–†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏")
        else:
            notes.append("–ú–æ–¥–µ–ª—å –∑–∞—Ç—Ä—É–¥–Ω—è–µ—Ç—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –∫—É–ª—å—Ç—É—Ä—ã")
            notes.append("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –±–æ–ª–µ–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
            
        return notes

class CropClassificationPredictor:
    """–ö–ª–∞—Å—Å –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∫—É–ª—å—Ç—É—Ä"""
    
    def __init__(self, model_path: str = None, device: str = None):
        self.device = device or settings.DEVICE
        self.model = None
        self.transform = self._get_transform()
        self.classes = settings.CROP_CLASSES
        self.classes_ru = settings.CROP_CLASSES_RU
        
        if model_path:
            self.load_model(model_path)
    
    def _get_transform(self) -> transforms.Compose:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π –¥–ª—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        return transforms.Compose([
            transforms.Resize((settings.IMAGE_SIZE, settings.IMAGE_SIZE)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])
    
    def load_model(self, model_path: str) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        self.model = CropClassifier(
            num_classes=len(self.classes),
            model_name=settings.CROP_MODEL_NAME,
            pretrained=False
        )
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏
        checkpoint = torch.load(model_path, map_location=self.device)
        if 'model_state_dict' in checkpoint:
            self.model.load_state_dict(checkpoint['model_state_dict'])
        else:
            self.model.load_state_dict(checkpoint)
            
        self.model.to(self.device)
        self.model.eval()
    
    def preprocess_image(self, image: Image.Image) -> torch.Tensor:
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
        tensor = self.transform(image)
        
        # –î–æ–±–∞–≤–ª—è–µ–º batch dimension
        tensor = tensor.unsqueeze(0)
        
        return tensor.to(self.device)
    
    def predict(self, image: Image.Image) -> Dict:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞ –∫—É–ª—å—Ç—É—Ä—ã —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏"""
        if self.model is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ load_model() –∏–ª–∏ —Å–æ–∑–¥–∞–π—Ç–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å.")
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        tensor = self.preprocess_image(image)
        
        # –ò–Ω—Ñ–µ—Ä–µ–Ω—Å
        with torch.no_grad():
            outputs = self.model(tensor)
            probabilities = torch.softmax(outputs, dim=1)
            predicted_class_idx = torch.argmax(probabilities, dim=1).item()
            confidence = probabilities[0][predicted_class_idx].item()
        
        # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤
        all_probabilities = {}
        all_probabilities_ru = {}
        
        for i, class_name in enumerate(self.classes):
            prob = probabilities[0][i].item()
            all_probabilities[class_name] = prob
            all_probabilities_ru[self.classes_ru[class_name]] = prob
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        probs_array = probabilities[0].cpu().numpy()
        sorted_probs = np.sort(probs_array)[::-1]  # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é
        
        # –†–∞–∑–Ω–æ—Å—Ç—å –º–µ–∂–¥—É –ø–µ—Ä–≤—ã–º –∏ –≤—Ç–æ—Ä—ã–º –º–µ—Å—Ç–æ–º
        confidence_gap = sorted_probs[0] - sorted_probs[1] if len(sorted_probs) > 1 else sorted_probs[0]
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        if confidence >= settings.HIGH_CONFIDENCE_THRESHOLD and confidence_gap > 0.3:
            confidence_level = "–í—ã—Å–æ–∫–∞—è"
            is_confident = True
        elif confidence >= settings.MEDIUM_CONFIDENCE_THRESHOLD and confidence_gap > 0.15:
            confidence_level = "–°—Ä–µ–¥–Ω—è—è"
            is_confident = True
        elif confidence >= settings.LOW_CONFIDENCE_THRESHOLD:
            confidence_level = "–ù–∏–∑–∫–∞—è"
            is_confident = False
        else:
            confidence_level = "–û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è"
            is_confident = False
        
        # –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –æ—á–µ–Ω—å –Ω–∏–∑–∫–∞—è, –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º "–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π" —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if confidence < settings.MIN_PREDICTION_CONFIDENCE:
            predicted_class = "uncertain"
            predicted_class_ru = "–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π —Ç–∏–ø"
            is_confident = False
            confidence_level = "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è"
        else:
            predicted_class = self.classes[predicted_class_idx]
            predicted_class_ru = self.classes_ru[predicted_class]
        
        return {
            "predicted_class": predicted_class,
            "predicted_class_ru": predicted_class_ru,
            "confidence": float(confidence),
            "confidence_level": confidence_level,
            "confidence_gap": float(confidence_gap),
            "probabilities": all_probabilities,
            "probabilities_ru": all_probabilities_ru,
            "is_confident": is_confident,
            "analysis_notes": self._generate_confidence_notes(confidence, confidence_gap, confidence_level)
        }
    
    def _generate_confidence_notes(self, confidence: float, confidence_gap: float, level: str) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ—è—Å–Ω–µ–Ω–∏–π –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
        notes = []
        
        if level == "–û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è" or level == "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è":
            notes.append("–ú–æ–¥–µ–ª—å –∑–∞—Ç—Ä—É–¥–Ω—è–µ—Ç—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –∫—É–ª—å—Ç—É—Ä—ã")
            notes.append("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –±–æ–ª–µ–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
            notes.append("–í–æ–∑–º–æ–∂–Ω–æ, –∫—É–ª—å—Ç—É—Ä–∞ –Ω–µ –≤—Ö–æ–¥–∏—Ç –≤ –æ–±—É—á–∞—é—â–∏–π –Ω–∞–±–æ—Ä")
        elif level == "–ù–∏–∑–∫–∞—è":
            notes.append("–ú–æ–¥–µ–ª—å –∏–º–µ–µ—Ç —Å–æ–º–Ω–µ–Ω–∏—è –≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
            notes.append("–†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏")
        elif level == "–°—Ä–µ–¥–Ω—è—è":
            notes.append("–ú–æ–¥–µ–ª—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —É–≤–µ—Ä–µ–Ω–∞ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ")
            notes.append("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä—Ç–æ–º")
        elif level == "–í—ã—Å–æ–∫–∞—è":
            notes.append("–ú–æ–¥–µ–ª—å –æ—á–µ–Ω—å —É–≤–µ—Ä–µ–Ω–∞ –≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
            notes.append("–†–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–∂–Ω–æ —Å—á–∏—Ç–∞—Ç—å –Ω–∞–¥–µ–∂–Ω—ã–º")
        
        if confidence_gap < 0.1:
            notes.append("–ú–∞–ª–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ - —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–µ–Ω")
        elif confidence_gap > 0.4:
            notes.append("–ë–æ–ª—å—à–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ - —á–µ—Ç–∫–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è")
            
        return notes
    
    def batch_predict(self, images: List[Image.Image]) -> List[Dict]:
        """–ü–∞–∫–µ—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —Å–ø–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        results = []
        for image in images:
            result = self.predict(image)
            results.append(result)
        return results

def create_enhanced_crop_classifier() -> ImprovedCropClassifier:
    """–°–æ–∑–¥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–º –∞–Ω–∞–ª–∏–∑–æ–º"""
    print("üéØ –°–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∫—É–ª—å—Ç—É—Ä...")
    
    enhanced_classifier = ImprovedCropClassifier()
    
    print("‚úÖ –£–ª—É—á—à–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
    print("‚úÖ –ê–Ω—Å–∞–º–±–ª–µ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω")
    print("‚úÖ –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –≤–∫–ª—é—á–µ–Ω")
    print("‚úÖ –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –∫—É–∫—É—Ä—É–∑—ã –∞–∫—Ç–∏–≤–Ω–∞")
    
    return enhanced_classifier

def create_pretrained_crop_classifier() -> CropClassificationPredictor:
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∫—É–ª—å—Ç—É—Ä"""
    predictor = CropClassificationPredictor()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≥–æ—Ç–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
    config_path = Path("data/models/pretrained_models_config.json")
    
    if config_path.exists():
        print("üì¶ –ù–∞–π–¥–µ–Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≥–æ—Ç–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π...")
        try:
            import json
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
            model_name = config["recommended_model"]
            model_config = config["models"][model_name]
            model_path = Path(model_config["path"])
            architecture = model_config["architecture"]
            
            if model_path.exists():
                print(f"‚úÖ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å {model_name}: {architecture}")
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞
                if model_config["type"] == "timm":
                    if "vit" in architecture:
                        # –î–ª—è ViT –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
                        print("üß† –ò—Å–ø–æ–ª—å–∑—É–µ–º Vision Transformer –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è")
                        model = CropClassifier(
                            num_classes=len(model_config["classes"]),
                            model_name=architecture,
                            pretrained=False
                        )
                    elif "convnext" in architecture:
                        # –î–ª—è ConvNeXt –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
                        print("üß† –ò—Å–ø–æ–ª—å–∑—É–µ–º ConvNeXt –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç—É—Ä")
                        model = CropClassifier(
                            num_classes=len(model_config["classes"]),
                            model_name=architecture,
                            pretrained=False
                        )
                    else:
                        # –î–ª—è –¥—Ä—É–≥–∏—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä
                        model = timm.create_model(
                            architecture, 
                            pretrained=False, 
                            num_classes=len(model_config["classes"])
                        )
                    
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
                    model.load_state_dict(torch.load(model_path, map_location=predictor.device))
                    model.to(predictor.device)
                    model.eval()
                    predictor.model = model
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–ª–∞—Å—Å—ã
                    predictor.classes = model_config["classes"]
                    predictor.classes_ru = {
                        "wheat": "–ø—à–µ–Ω–∏—Ü–∞",
                        "corn": "–∫—É–∫—É—Ä—É–∑–∞", 
                        "barley": "—è—á–º–µ–Ω—å"
                    }
                    
                    # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–æ–¥–µ–ª–∏
                    if "vit" in architecture or "convnext" in architecture:
                        # –î–ª—è ViT –∏ ConvNeXt –Ω—É–∂–Ω—ã –¥—Ä—É–≥–∏–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
                        predictor.transform = transforms.Compose([
                            transforms.Resize((224, 224)),
                            transforms.ToTensor(),
                            transforms.Normalize(
                                mean=[0.485, 0.456, 0.406],
                                std=[0.229, 0.224, 0.225]
                            )
                        ])
                    
                    print(f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} ({architecture}) –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
                    return predictor
                    
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≥–æ—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {e}")
            print("üîÑ –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É –º–µ—Ç–æ–¥—É...")
    
    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å, —Å–æ–∑–¥–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é
    print("‚öôÔ∏è –°–æ–∑–¥–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∫—É–ª—å—Ç—É—Ä...")
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å EfficientNet
    model = CropClassifier(
        num_classes=len(predictor.classes),
        model_name=settings.CROP_MODEL_NAME,
        pretrained=True
    )
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    model_path = Path("data/models/pretrained/crop_classifier_fallback.pth")
    model_path.parent.mkdir(parents=True, exist_ok=True)
    torch.save(model.state_dict(), model_path)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model.load_state_dict(torch.load(model_path, map_location=predictor.device))
    model.to(predictor.device)
    model.eval()
    predictor.model = model
    
    print("‚úÖ –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
    return predictor 

class SmartCropClassifier:
    """–£–º–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä, –∫–æ—Ç–æ—Ä—ã–π –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É"""
    
    def __init__(self, device: str = None, prefer_advanced: bool = True):
        self.device = device or settings.DEVICE
        self.prefer_advanced = prefer_advanced
        self.classifier = None
        self.classifier_type = None
        
        self._initialize_best_classifier()
    
    def _initialize_best_classifier(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ª—É—á—à–∏–π –¥–æ—Å—Ç—É–ø–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä"""
        
        if self.prefer_advanced and ADVANCED_CLASSIFIER_AVAILABLE:
            try:
                print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è...")
                self.classifier = NextGenCropClassifier(device=self.device)
                self.classifier_type = "NextGen"
                print("‚úÖ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!")
                print("üéØ –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: Swin Transformer, Vision Transformer, EfficientNetV2")
                return
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä: {e}")
                print("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ —É–ª—É—á—à–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä...")
        
        # Fallback –Ω–∞ —É–ª—É—á—à–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
        try:
            print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞...")
            self.classifier = ImprovedCropClassifier(device=self.device)
            self.classifier_type = "Improved"
            print("‚úÖ –£–ª—É—á—à–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!")
            print("üéØ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∞–Ω—Å–∞–º–±–ª—å: ConvNeXt, EfficientNet-B4, ResNet50")
        except Exception as e:
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∏ –æ–¥–∏–Ω –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä: {e}")
            raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–∏—Å—Ç–µ–º—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
    
    def predict(self, image: Image.Image) -> Dict:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ª—É—á—à–µ–≥–æ –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞"""
        if self.classifier is None:
            raise RuntimeError("–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        try:
            result = self.classifier.predict(image)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∏–ø–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
            if "analysis_notes" not in result:
                result["analysis_notes"] = []
            
            classifier_info = {
                "NextGen": "üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ù–û–í–û–ì–û –ü–û–ö–û–õ–ï–ù–ò–Ø —Å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞–º–∏",
                "Improved": "üîß –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –£–õ–£–ß–®–ï–ù–ù–´–ô –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å –∞–Ω—Å–∞–º–±–ª–µ–º –º–æ–¥–µ–ª–µ–π"
            }
            
            result["analysis_notes"].insert(0, classifier_info.get(self.classifier_type, "ü§ñ –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä"))
            result["classifier_type"] = self.classifier_type
            
            return result
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–µ {self.classifier_type}: {e}")
            
            # –ï—Å–ª–∏ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –ø—Ä–æ–±—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π
            if self.classifier_type == "NextGen":
                print("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω—ã–π —É–ª—É—á—à–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä...")
                try:
                    self.classifier = ImprovedCropClassifier(device=self.device)
                    self.classifier_type = "Improved"
                    result = self.classifier.predict(image)
                    result["analysis_notes"] = ["‚ö†Ô∏è –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä"] + result.get("analysis_notes", [])
                    result["classifier_type"] = self.classifier_type
                    return result
                except Exception as e2:
                    print(f"‚ùå –†–µ–∑–µ—Ä–≤–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ç–æ–∂–µ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç: {e2}")
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É
            return {
                "predicted_class": "error",
                "predicted_class_ru": "–æ—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏",
                "confidence": 0.0,
                "confidence_level": "–û—à–∏–±–∫–∞",
                "probabilities": {"error": 1.0},
                "probabilities_ru": {"–æ—à–∏–±–∫–∞": 1.0},
                "is_confident": False,
                "analysis_notes": [f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}"],
                "classifier_type": "error"
            }
    
    def get_classifier_info(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—É—â–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–µ"""
        return {
            "type": self.classifier_type,
            "available_advanced": ADVANCED_CLASSIFIER_AVAILABLE,
            "device": self.device,
            "description": {
                "NextGen": "–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è —Å Swin Transformer, Vision Transformer, EfficientNetV2",
                "Improved": "–£–ª—É—á—à–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å –∞–Ω—Å–∞–º–±–ª–µ–º ConvNeXt, EfficientNet-B4, ResNet50"
            }.get(self.classifier_type, "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø")
        } 