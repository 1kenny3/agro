#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è—Ö –∏–∑ –ø–∞–ø–∫–∏ photo/
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
import json
import numpy as np
from pathlib import Path
import cv2

from train_improved_model import EnhancedCropClassifier

class TrainedModelPredictor:
    """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    
    def __init__(self, model_path="data/models/enhanced_crop_classifier.pth"):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model_path = model_path
        self.model = None
        self.class_to_idx = None
        self.idx_to_class = None
        
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        self.load_model()
    
    def load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        if not Path(self.model_path).exists():
            print(f"‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.model_path}")
            print("–°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å: python train_improved_model.py")
            return
        
        print(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ {self.model_path}...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º checkpoint
        checkpoint = torch.load(self.model_path, map_location=self.device)
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
        self.model = EnhancedCropClassifier(num_classes=3, use_visual_features=True)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.to(self.device)
        self.model.eval()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ –∫–ª–∞—Å—Å–æ–≤
        self.class_to_idx = checkpoint.get('class_to_idx', {'wheat': 0, 'corn': 1, 'barley': 2})
        self.idx_to_class = {v: k for k, v in self.class_to_idx.items()}
        
        best_accuracy = checkpoint.get('val_acc', 0)
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞! –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: {best_accuracy:.2f}%")
    
    def extract_visual_features(self, image_path):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        try:
            image = Image.open(image_path)
            img_array = np.array(image.convert('RGB'))
            height, width = img_array.shape[:2]
            
            # –¶–≤–µ—Ç–æ–≤–æ–π –∞–Ω–∞–ª–∏–∑
            hsv = cv2.cvtColor(img_array, cv2.COLOR_RGB2HSV)
            
            # –ê–Ω–∞–ª–∏–∑ –∑–µ–ª–µ–Ω—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π
            green_mask = cv2.inRange(hsv, np.array([40, 40, 40]), np.array([80, 255, 255]))
            green_ratio = np.sum(green_mask > 0) / green_mask.size
            
            # –ê–Ω–∞–ª–∏–∑ –∂–µ–ª—Ç–æ-–∫–æ—Ä–∏—á–Ω–µ–≤—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π
            yellow_mask = cv2.inRange(hsv, np.array([10, 50, 50]), np.array([30, 255, 255]))
            yellow_ratio = np.sum(yellow_mask > 0) / yellow_mask.size
            
            # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç—É—Ä—ã
            gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
            
            # –ü–æ–∏—Å–∫ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä
            sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
            sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            angles = np.arctan2(sobely, sobelx)
            vertical_lines = np.sum(np.abs(angles) < np.pi/6) / angles.size
            
            # –ü–ª–æ—Ç–Ω–æ—Å—Ç—å –∫—Ä–∞–µ–≤
            edges = cv2.Canny(gray, 50, 150)
            edge_density = np.sum(edges > 0) / edges.size
            
            # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω
            aspect_ratio = height / width if width > 0 else 1.0
            
            return torch.tensor([
                green_ratio, yellow_ratio, vertical_lines, edge_density, aspect_ratio
            ], dtype=torch.float32)
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            return torch.zeros(5, dtype=torch.float32)
    
    def predict(self, image_path):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        if self.model is None:
            return None
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = Image.open(image_path).convert('RGB')
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image_tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            visual_features = self.extract_visual_features(image_path).unsqueeze(0).to(self.device)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            with torch.no_grad():
                outputs = self.model(image_tensor, visual_features)
                probabilities = torch.softmax(outputs, dim=1)
                predicted_idx = torch.argmax(probabilities, dim=1).item()
                confidence = probabilities[0][predicted_idx].item()
            
            predicted_class = self.idx_to_class[predicted_idx]
            
            # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
            all_probabilities = {}
            for idx, class_name in self.idx_to_class.items():
                all_probabilities[class_name] = probabilities[0][idx].item()
            
            class_names_ru = {'wheat': '–ø—à–µ–Ω–∏—Ü–∞', 'corn': '–∫—É–∫—É—Ä—É–∑–∞', 'barley': '—è—á–º–µ–Ω—å'}
            
            return {
                'predicted_class': predicted_class,
                'predicted_class_ru': class_names_ru.get(predicted_class, predicted_class),
                'confidence': confidence,
                'probabilities': all_probabilities,
                'visual_features': {
                    'green_ratio': visual_features[0][0].item(),
                    'yellow_ratio': visual_features[0][1].item(),
                    'vertical_lines': visual_features[0][2].item(),
                    'edge_density': visual_features[0][3].item(),
                    'aspect_ratio': visual_features[0][4].item()
                }
            }
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è {image_path}: {e}")
            return None

def test_on_original_photos():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è—Ö"""
    print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –û–ë–£–ß–ï–ù–ù–û–ô –ú–û–î–ï–õ–ò")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä
    predictor = TrainedModelPredictor()
    
    if predictor.model is None:
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    with open("photo_analysis_results.json", 'r', encoding='utf-8') as f:
        original_results = json.load(f)
    
    print(f"\nüìÅ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ {len(original_results)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö...")
    
    correct_predictions = 0
    total_predictions = 0
    
    results_comparison = []
    
    for result in original_results:
        file_path = result['file_info']['path']
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª—ã —Å –æ—à–∏–±–∫–∞–º–∏
        if result.get('visual_features', {}).get('error'):
            continue
        
        print(f"\nüì∏ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: {Path(file_path).name}")
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        trained_prediction = predictor.predict(file_path)
        
        if trained_prediction is None:
            continue
        
        # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        original_manual = result['manual_identification']
        original_ml = result['ml_prediction']
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
        is_correct_manual = trained_prediction['predicted_class'] == original_manual['class']
        is_correct_ml = trained_prediction['predicted_class'] == original_ml['class']
        
        total_predictions += 1
        if is_correct_manual:
            correct_predictions += 1
        
        print(f"   üë®‚Äçüåæ –†—É—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: {original_manual['class_ru']}")
        print(f"   ü§ñ –°—Ç–∞—Ä–∞—è –º–æ–¥–µ–ª—å: {original_ml['class_ru']} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {original_ml['confidence']:.2f})")
        print(f"   üéØ –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å: {trained_prediction['predicted_class_ru']} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {trained_prediction['confidence']:.2f})")
        
        agreement_manual = "‚úÖ" if is_correct_manual else "‚ùå"
        agreement_ml = "‚úÖ" if is_correct_ml else "‚ùå"
        print(f"   {agreement_manual} –°–æ–≥–ª–∞—Å–∏–µ —Å —Ä—É—á–Ω–æ–π –æ—Ü–µ–Ω–∫–æ–π")
        print(f"   {agreement_ml} –°–æ–≥–ª–∞—Å–∏–µ —Å–æ —Å—Ç–∞—Ä–æ–π –º–æ–¥–µ–ª—å—é")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        results_comparison.append({
            'file': Path(file_path).name,
            'manual_class': original_manual['class'],
            'old_ml_class': original_ml['class'],
            'trained_class': trained_prediction['predicted_class'],
            'trained_confidence': trained_prediction['confidence'],
            'correct_vs_manual': is_correct_manual,
            'correct_vs_old_ml': is_correct_ml
        })
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    accuracy_vs_manual = correct_predictions / total_predictions * 100 if total_predictions > 0 else 0
    
    print(f"\nüìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"   –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å vs —Ä—É—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: {accuracy_vs_manual:.1f}% ({correct_predictions}/{total_predictions})")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª–∞—Å—Å–∞–º
    class_stats = {}
    for result in results_comparison:
        manual_class = result['manual_class']
        if manual_class not in class_stats:
            class_stats[manual_class] = {'total': 0, 'correct': 0}
        
        class_stats[manual_class]['total'] += 1
        if result['correct_vs_manual']:
            class_stats[manual_class]['correct'] += 1
    
    print("\n   –¢–æ—á–Ω–æ—Å—Ç—å –ø–æ –∫–ª–∞—Å—Å–∞–º:")
    class_names_ru = {'wheat': '–ø—à–µ–Ω–∏—Ü–∞', 'corn': '–∫—É–∫—É—Ä—É–∑–∞', 'barley': '—è—á–º–µ–Ω—å'}
    for class_name, stats in class_stats.items():
        accuracy = stats['correct'] / stats['total'] * 100 if stats['total'] > 0 else 0
        class_ru = class_names_ru.get(class_name, class_name)
        print(f"     {class_ru}: {accuracy:.1f}% ({stats['correct']}/{stats['total']})")
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–æ —Å—Ç–∞—Ä–æ–π –º–æ–¥–µ–ª—å—é
    old_model_agreements = sum(1 for r in results_comparison if r['correct_vs_old_ml'])
    old_model_accuracy = old_model_agreements / total_predictions * 100 if total_predictions > 0 else 0
    
    print(f"\n   –°–æ–≥–ª–∞—Å–∏–µ —Å —Å—Ç–∞—Ä–æ–π –º–æ–¥–µ–ª—å—é: {old_model_accuracy:.1f}% ({old_model_agreements}/{total_predictions})")
    
    # –£–ª—É—á—à–µ–Ω–∏—è
    improvement = accuracy_vs_manual - 57.1  # 57.1% –±—ã–ª–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º –∞–Ω–∞–ª–∏–∑–µ
    print(f"   –£–ª—É—á—à–µ–Ω–∏–µ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–º: {improvement:+.1f}%")
    
    return results_comparison

def test_specific_image(image_path):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    print(f"\nüîç –î–ï–¢–ê–õ–¨–ù–´–ô –¢–ï–°–¢ –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø: {Path(image_path).name}")
    print("=" * 60)
    
    predictor = TrainedModelPredictor()
    
    if predictor.model is None:
        return
    
    result = predictor.predict(image_path)
    
    if result:
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
        print(f"   –ö—É–ª—å—Ç—É—Ä–∞: {result['predicted_class_ru']}")
        print(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']:.3f}")
        
        print(f"\nüìà –í—Å–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏:")
        class_names_ru = {'wheat': '–ø—à–µ–Ω–∏—Ü–∞', 'corn': '–∫—É–∫—É—Ä—É–∑–∞', 'barley': '—è—á–º–µ–Ω—å'}
        for class_name, prob in result['probabilities'].items():
            class_ru = class_names_ru.get(class_name, class_name)
            print(f"   {class_ru}: {prob:.3f}")
        
        print(f"\nüîç –í–∏–∑—É–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:")
        for feature, value in result['visual_features'].items():
            print(f"   {feature}: {value:.3f}")
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")

if __name__ == "__main__":
    print("üéØ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –û–ë–£–ß–ï–ù–ù–û–ô –ú–û–î–ï–õ–ò –ù–ê –§–û–¢–û–ì–†–ê–§–ò–Ø–•")
    print("üåæ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    print("=" * 65)
    
    try:
        # –û—Å–Ω–æ–≤–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        comparison_results = test_on_original_photos()
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        photo_dir = Path("photo")
        image_files = [f for f in photo_dir.iterdir() 
                      if f.is_file() and f.suffix.lower() in ['.jpg', '.jpeg', '.png']]
        
        if image_files:
            test_image = image_files[0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            test_specific_image(test_image)
        
        print(f"\nüéâ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
        print(f"‚úÖ –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è—Ö")
        
    except Exception as e:
        print(f"üí• –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc() 